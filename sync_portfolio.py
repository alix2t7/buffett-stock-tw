#!/usr/bin/env python3
"""
æŒè‚¡åŒæ­¥ä¸»æ§è…³æœ¬ v2ï¼ˆæ–¹æ¡ˆ B â€” çµ±ä¸€æŠ“å–ï¼‰

å°‡ 4 æ”¯ fetch è…³æœ¬çš„é‚è¼¯åˆä½µç‚ºå–®ä¸€è¿´åœˆï¼š
æ¯æ”¯è‚¡ç¥¨åªå»ºç«‹ä¸€æ¬¡ yf.Tickerï¼Œä¸€æ¬¡æŠ“å®Œæ‰€æœ‰è³‡æ–™ã€‚

åŠŸèƒ½ï¼š
  â€¢ diff sync  â€” æ¯”å° STOCK_LIST vs DBï¼Œè‡ªå‹•æ–°å¢/ç§»é™¤
  â€¢ --add       â€” å¾å„€è¡¨æ¿ä¸€éµæ–°å¢è‚¡ç¥¨ï¼ˆæ›´æ–° config + æŠ“å– + é‡ç”Ÿ JSONï¼‰
  â€¢ --remove    â€” å¾å„€è¡¨æ¿ä¸€éµç§»é™¤è‚¡ç¥¨ï¼ˆæ›´æ–° config + æ¸… DB + é‡ç”Ÿ JSONï¼‰
  â€¢ --refresh   â€” å¼·åˆ¶å…¨éƒ¨é‡æŠ“
  â€¢ --regen-only â€” åªé‡æ–°ç”Ÿæˆ JSON

Usage:
  python3 sync_portfolio.py                                 # diff sync
  python3 sync_portfolio.py --add 2330 --name å°ç©é›» --sector åŠå°é«”
  python3 sync_portfolio.py --remove 2330
  python3 sync_portfolio.py --refresh
  python3 sync_portfolio.py --dry-run
  python3 sync_portfolio.py --regen-only
"""

import argparse
import json
import os
import re
import time
from datetime import datetime

from stock_config import (
    STOCK_LIST, STOCK_NAME_MAPPING, SECTOR_MAPPING,
    DB_PATH, init_database,
)
from fetchers.ticker import resolve_ticker
from fetchers.price import save_current_snapshot, save_historical_prices
from fetchers.fundamentals import save_annual_fundamentals, save_quarterly_and_fix
from db.crud import get_db_tickers, remove_ticker_from_db
from exporters.stock_data import generate_stock_data_json
from exporters.history import export_history_json

# â”€â”€â”€ Constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BACKFILL_DAYS = 365
REQUEST_DELAY = 1.0
TICKER_PATTERN = re.compile(r'^\d{4,6}$')
MAX_NAME_LEN = 50


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Â§ Config Persistence
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _config_local_path():
    return os.path.join(os.path.dirname(os.path.abspath(__file__)),
                        'stock_config.local.json')


def _write_config_local():
    """å°‡ç›®å‰çš„ STOCK_LIST / NAME / SECTOR å¯«å› stock_config.local.jsonï¼ˆåŸå­å¯«å…¥ï¼‰"""
    path = _config_local_path()
    data = {
        "STOCK_LIST": sorted(STOCK_LIST),
        "STOCK_NAME_MAPPING": dict(sorted(STOCK_NAME_MAPPING.items())),
        "SECTOR_MAPPING": dict(sorted(SECTOR_MAPPING.items())),
    }
    tmp_path = path + '.tmp'
    with open(tmp_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
        f.write('\n')
        f.flush()
        os.fsync(f.fileno())
    os.replace(tmp_path, path)  # åŸå­é‡å‘½åï¼Œé¿å…å¯«å…¥ä¸­æ–·å°è‡´ä¸ä¸€è‡´


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Â§ Unified Fetch â€” ä¸€æ”¯ Ticker æŠ“å®Œå…¨éƒ¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def unified_fetch_one(ticker_code, *, backfill_days=BACKFILL_DAYS):
    """
    å»ºç«‹ä¸€å€‹ yf.Ticker ç‰©ä»¶ï¼Œä¸€æ¬¡æŠ“å®Œï¼š
      1) å³æ™‚å ±åƒ¹  â†’ stock_history (today)
      2) å¹´å ±      â†’ annual_fundamentals
      3) æ­·å²èµ°å‹¢  â†’ stock_history (backfill)
      4) å­£å ±ä¿®æ­£  â†’ fundamentals_history + UPDATE stock_history

    å›å‚³ auto-detected nameï¼ˆæˆåŠŸï¼‰æˆ– Noneï¼ˆå¤±æ•—ï¼‰ã€‚
    """
    name = STOCK_NAME_MAPPING.get(ticker_code, ticker_code)
    print(f"\n  ğŸ“¡ {ticker_code} ({name})")

    stock, symbol = resolve_ticker(ticker_code)
    if stock is None:
        print(f"    âŒ ç„¡æ³•è§£æï¼ˆ.TW / .TWO å‡ç„¡ï¼‰")
        return None

    print(f"    âœ“ ä½¿ç”¨ {symbol}")
    info = stock.info

    detected_name = info.get('shortName', info.get('longName', ticker_code))

    # Step 1: å³æ™‚å ±åƒ¹
    save_current_snapshot(ticker_code, info)

    # Step 2: å¹´å ±
    save_annual_fundamentals(ticker_code, stock)

    # Step 3: æ­·å²èµ°å‹¢ï¼ˆéœ€åœ¨ Step 4 å‰ï¼Œå› ç‚º Step 4 æœƒ UPDATE é€™äº› rowsï¼‰
    save_historical_prices(ticker_code, stock, symbol, info, backfill_days)

    # Step 4: å­£å ±ä¿®æ­£
    save_quarterly_and_fix(ticker_code, stock)

    return detected_name


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Â§ JSON Regeneration
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def regenerate_json():
    """ç›´æ¥å‘¼å« exporters æ¨¡çµ„é‡æ–°ç”Ÿæˆ JSONï¼ˆå–ä»£ subprocess æ–¹å¼ï¼‰ã€‚"""
    errors = []
    print("\n  ğŸ”„ é‡æ–°ç”Ÿæˆ JSONï¼š")
    print("    â–¸ stock_data.json ...", end=" ", flush=True)
    try:
        generate_stock_data_json()
        print("âœ…")
    except Exception as e:
        print(f"âŒ {e}")
        errors.append(f"stock_data.json: {e}")

    print("    â–¸ history_all.json ...", end=" ", flush=True)
    try:
        export_history_json(".")
        print("âœ…")
    except Exception as e:
        print(f"âŒ {e}")
        errors.append(f"history_all.json: {e}")

    if errors:
        print(f"\n  âš ï¸ JSON é‡æ–°ç”Ÿæˆéƒ¨åˆ†å¤±æ•—ï¼š{'; '.join(errors)}")
    return len(errors) == 0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Â§ Main
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    parser = argparse.ArgumentParser(description='æŒè‚¡åŒæ­¥ä¸»æ§ v2ï¼ˆçµ±ä¸€æŠ“å–ï¼‰')
    parser.add_argument('--add', type=str, metavar='TICKER',
                        help='æ–°å¢è‚¡ç¥¨ä»£ç¢¼')
    parser.add_argument('--remove', type=str, metavar='TICKER',
                        help='ç§»é™¤è‚¡ç¥¨ä»£ç¢¼')
    parser.add_argument('--name', type=str,
                        help='æ–°å¢è‚¡ç¥¨åç¨±ï¼ˆå¯é¸ï¼Œè‡ªå‹•åµæ¸¬ï¼‰')
    parser.add_argument('--sector', type=str, default='',
                        help='æ–°å¢è‚¡ç¥¨ç”¢æ¥­ï¼ˆå¯é¸ï¼Œé è¨­ "é›»å­"ï¼‰')
    parser.add_argument('--refresh', action='store_true',
                        help='å¼·åˆ¶å…¨éƒ¨é‡æŠ“')
    parser.add_argument('--dry-run', action='store_true',
                        help='åƒ…é¡¯ç¤ºå·®ç•°ï¼Œä¸åŸ·è¡Œ')
    parser.add_argument('--regen-only', action='store_true',
                        help='åªé‡æ–°ç”Ÿæˆ JSON')
    args = parser.parse_args()

    print("=" * 60)
    print("ğŸ”„ æŒè‚¡åŒæ­¥ä¸»æ§ v2")
    print(f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    # â”€â”€ é¦–æ¬¡ä½¿ç”¨ï¼šè‡ªå‹•å»ºç«‹ stock_config.local.json â”€â”€
    config_local = _config_local_path()
    config_example = os.path.join(os.path.dirname(os.path.abspath(__file__)),
                                  'stock_config.example.json')
    if not os.path.isfile(config_local) and os.path.isfile(config_example):
        import shutil
        shutil.copy2(config_example, config_local)
        print(f"\nğŸ“‹ é¦–æ¬¡ä½¿ç”¨ï¼šå·²è‡ªå‹•å»ºç«‹ stock_config.local.jsonï¼ˆé è¨­ç¯„ä¾‹è‚¡ç¥¨ï¼‰")
        print(f"   è«‹ç·¨è¼¯ {config_local} å¡«å…¥ä½ çš„æŒè‚¡ä»£ç¢¼\n")

    init_database()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Mode: Add â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if args.add:
        ticker = args.add.strip()
        user_name = args.name
        user_sector = args.sector or 'é›»å­'

        # S-3: è¼¸å…¥é©—è­‰
        if not TICKER_PATTERN.match(ticker):
            print(f"\nâŒ ç„¡æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼æ ¼å¼ï¼š{ticker}ï¼ˆæ‡‰ç‚º 4-6 ä½æ•¸å­—ï¼‰")
            return
        if user_name and len(user_name) > MAX_NAME_LEN:
            print(f"\nâŒ åç¨±éé•·ï¼ˆæœ€å¤§ {MAX_NAME_LEN} å­—ï¼‰")
            return
        if user_sector and len(user_sector) > MAX_NAME_LEN:
            print(f"\nâŒ ç”¢æ¥­åç¨±éé•·ï¼ˆæœ€å¤§ {MAX_NAME_LEN} å­—ï¼‰")
            return

        print(f"\nğŸ†• æ–°å¢è‚¡ç¥¨: {ticker}")

        was_new = ticker not in STOCK_LIST
        if was_new:
            STOCK_LIST.append(ticker)
        STOCK_NAME_MAPPING.setdefault(ticker, user_name or ticker)
        SECTOR_MAPPING.setdefault(ticker, user_sector)

        start = time.time()
        detected_name = unified_fetch_one(ticker)

        if detected_name:
            if not user_name and detected_name != ticker:
                STOCK_NAME_MAPPING[ticker] = detected_name
            elif user_name:
                STOCK_NAME_MAPPING[ticker] = user_name
            _write_config_local()
            regenerate_json()
            final_name = STOCK_NAME_MAPPING[ticker]
            print(f"\n{'='*60}")
            print(f"âœ… {ticker} ({final_name}) æ–°å¢å®Œæˆï¼è€—æ™‚ {time.time()-start:.1f} ç§’")
            print(f"   åç¨±: {final_name}")
            print(f"   ç”¢æ¥­: {SECTOR_MAPPING[ticker]}")
            print(f"{'='*60}")
        else:
            if was_new:
                STOCK_LIST.remove(ticker)
                STOCK_NAME_MAPPING.pop(ticker, None)
                SECTOR_MAPPING.pop(ticker, None)
            print(f"\nâŒ {ticker} æ–°å¢å¤±æ•—ï¼ˆç„¡æ³•å¾ yfinance å–å¾—è³‡æ–™ï¼‰")
        return

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Mode: Remove â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if args.remove:
        ticker = args.remove.strip()
        if not TICKER_PATTERN.match(ticker):
            print(f"\nâŒ ç„¡æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼æ ¼å¼ï¼š{ticker}ï¼ˆæ‡‰ç‚º 4-6 ä½æ•¸å­—ï¼‰")
            return
        name = STOCK_NAME_MAPPING.get(ticker, ticker)
        print(f"\nğŸ—‘ï¸  ç§»é™¤è‚¡ç¥¨: {ticker} ({name})")

        deleted = remove_ticker_from_db(ticker)
        print(f"   åˆªé™¤ DB è¨˜éŒ„: {deleted} ç­†")

        if ticker in STOCK_LIST:
            STOCK_LIST.remove(ticker)
        STOCK_NAME_MAPPING.pop(ticker, None)
        SECTOR_MAPPING.pop(ticker, None)
        _write_config_local()
        print("   å·²å¾ stock_config.local.json ç§»é™¤")

        regenerate_json()
        print(f"\n{'='*60}")
        print(f"âœ… {ticker} ({name}) å·²ç§»é™¤")
        print(f"{'='*60}")
        return

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Mode: Regen Only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if args.regen_only:
        regenerate_json()
        print("\nâœ… JSON é‡æ–°ç”Ÿæˆå®Œæˆ")
        return

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Mode: Diff Sync â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    config_set = set(STOCK_LIST)
    db_set = get_db_tickers()
    added = config_set - db_set
    removed = db_set - config_set
    existing = config_set & db_set

    print(f"\nğŸ“‹ STOCK_LIST: {len(config_set)} æª”")
    print(f"ğŸ’¾ DB ç¾æœ‰:    {len(db_set)} æª”")
    print(f"{'â”€' * 40}")
    print(f"  ğŸ†• æ–°å¢: {len(added)} æª”  {sorted(added) if added else ''}")
    print(f"  ğŸ—‘ï¸  ç§»é™¤: {len(removed)} æª”  {sorted(removed) if removed else ''}")
    print(f"  âœ“  ä¿ç•™: {len(existing)} æª”")

    if args.dry_run:
        print("\nğŸ“ [Dry Run] åƒ…é¡¯ç¤ºå·®ç•°ï¼ŒæœªåŸ·è¡Œä»»ä½•æ“ä½œ")
        regenerate_json()
        return

    start_time = time.time()

    # æ–°å¢
    failures = []
    if added:
        print(f"\n{'â”€' * 40}")
        print(f"ğŸ†• æ–°å¢ {len(added)} æª”è‚¡ç¥¨ï¼ˆçµ±ä¸€æŠ“å–ï¼‰")
        for i, ticker in enumerate(sorted(added)):
            try:
                unified_fetch_one(ticker)
            except Exception as e:
                print(f"    âš ï¸ {ticker} å¤±æ•—: {e}")
                failures.append(ticker)
            if i < len(added) - 1:
                time.sleep(REQUEST_DELAY)

    # ç§»é™¤å¹½éˆè‚¡
    if removed:
        print(f"\n{'â”€' * 40}")
        print(f"ğŸ—‘ï¸  ç§»é™¤ {len(removed)} æª”å¹½éˆè‚¡")
        for ticker in sorted(removed):
            try:
                n = remove_ticker_from_db(ticker)
                print(f"  âœ— {ticker}: åˆªé™¤ {n} ç­†")
            except Exception as e:
                print(f"  âš ï¸ {ticker} ç§»é™¤å¤±æ•—: {e}")
                failures.append(ticker)

    # å¼·åˆ¶é‡æŠ“
    if args.refresh and existing:
        print(f"\n{'â”€' * 40}")
        print(f"ğŸ”„ é‡æ–°æŠ“å– {len(existing)} æª”æ—¢æœ‰è‚¡ç¥¨ï¼ˆçµ±ä¸€æŠ“å–ï¼‰")
        for i, ticker in enumerate(sorted(existing)):
            try:
                unified_fetch_one(ticker)
            except Exception as e:
                print(f"    âš ï¸ {ticker} å¤±æ•—: {e}")
                failures.append(ticker)
            if i < len(existing) - 1:
                time.sleep(REQUEST_DELAY)

    # JSON
    regenerate_json()

    duration = time.time() - start_time
    print(f"\n{'=' * 60}")
    print(f"âœ… åŒæ­¥å®Œæˆï¼è€—æ™‚ {duration:.1f} ç§’")
    if added:
        print(f"   ğŸ†• æ–°å¢: {', '.join(sorted(added))}")
    if removed:
        print(f"   ğŸ—‘ï¸  ç§»é™¤: {', '.join(sorted(removed))}")
    if failures:
        print(f"   âš ï¸  å¤±æ•—: {', '.join(failures)}")
    print(f"{'=' * 60}")


if __name__ == '__main__':
    main()
