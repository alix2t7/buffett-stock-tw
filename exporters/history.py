"""
exporters.history â€” å¾ SQLite æ­·å²è³‡æ–™åŒ¯å‡º history_all.json

è¼¸å‡ºæ ¼å¼ï¼ˆhistory_all.jsonï¼‰ï¼š
{
  "generatedAt": "2024-01-02T12:34:56",
  "history": {
    "1537": [
      { "date": "2024-01-02", "price": 218.5, "eps": 14.2, ... },
      ...
    ]
  }
}
"""

import json
import os
import sqlite3
import contextlib
from datetime import datetime
from typing import Any, Dict, List

from stock_config import STOCK_LIST, DB_PATH


def _atomic_write_json(path, data):
    """åŸå­å¯«å…¥ JSONï¼štmp + fsync + os.replaceï¼Œé¿å…å¯«å…¥ä¸­æ–·ç”¢ç”Ÿæå£æª”ã€‚"""
    tmp = path + '.tmp'
    with open(tmp, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
        f.write('\n')
        f.flush()
        os.fsync(f.fileno())
    os.replace(tmp, path)


def fetch_history_from_db() -> Dict[str, List[Dict[str, Any]]]:
    """
    å¾ SQLite è®€å–æ‰€æœ‰æˆåŠŸçš„æ­·å²è¨˜éŒ„ï¼Œä¾ ticker åˆ†çµ„ã€‚
    åªä¿ç•™ STOCK_LIST ä¸­çš„è‚¡ç¥¨ã€‚
    """
    if not os.path.exists(DB_PATH):
        print(f"âŒ æ‰¾ä¸åˆ°è³‡æ–™åº«æª”æ¡ˆï¼š{DB_PATH}")
        return {}

    with contextlib.closing(sqlite3.connect(DB_PATH)) as conn:
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        cursor.execute("""
            SELECT
                ticker, price, eps, pe, pb, roe,
                dividend_yield, growth_rate, fetch_time
            FROM stock_history
            WHERE fetch_error = 0
            ORDER BY ticker, fetch_time ASC
        """)

        rows = cursor.fetchall()

    history: Dict[str, List[Dict[str, Any]]] = {}

    for row in rows:
        ticker = row["ticker"]
        fetch_time = row["fetch_time"]
        if not fetch_time:
            continue

        date_str = str(fetch_time).split(" ")[0]

        point = {
            "date": date_str,
            "price": row["price"],
            "eps": row["eps"],
            "pe": row["pe"],
            "pb": row["pb"],
            "roe": row["roe"],
            "dividendYield": row["dividend_yield"],
            "growthRate": row["growth_rate"],
        }

        history.setdefault(ticker, []).append(point)

    # ä¾æ—¥æœŸæ’åº
    for ticker, points in history.items():
        points.sort(key=lambda p: p["date"])

    # åªä¿ç•™ STOCK_LIST ä¸­çš„è‚¡ç¥¨
    active_set = set(STOCK_LIST)
    history = {t: pts for t, pts in history.items() if t in active_set}

    return history


def export_history_json(output_root: str = ".") -> str:
    """
    åŒ¯å‡º history_all.json åˆ° public/ ç›®éŒ„ã€‚

    Args:
        output_root: å°ˆæ¡ˆæ ¹ç›®éŒ„

    Returns:
        public/history_all.json çš„å¯¦éš›è·¯å¾‘
    """
    history = fetch_history_from_db()

    total_points = sum(len(points) for points in history.values())
    print(f"ğŸ“Š å…±æœ‰ {len(history)} æª”è‚¡ç¥¨ï¼Œç¸½è¨ˆ {total_points} ç­†æ­·å²è¨˜éŒ„")

    now = datetime.now().isoformat()
    payload = {
        "generatedAt": now,
        "history": history,
    }

    root = os.path.abspath(output_root)
    public_dir = os.path.join(root, "public")
    os.makedirs(public_dir, exist_ok=True)

    # 1. è¼¸å‡º history_all.jsonï¼ˆä¿ç•™åŸæœ‰æ ¼å¼ï¼Œæ–¹ä¾¿å‰ç«¯éæ¸¡ï¼‰
    public_path = os.path.join(public_dir, "history_all.json")
    try:
        _atomic_write_json(public_path, payload)
        print(f"âœ… å·²è¼¸å‡ºæ­·å² JSONï¼š{public_path}")
    except Exception as e:
        print(f"âš ï¸ å¯«å…¥ {public_path} å¤±æ•—ï¼š{e}")

    # 2. æ‹†åˆ†ç‚º public/history/{ticker}.json
    history_dir = os.path.join(public_dir, "history")
    os.makedirs(history_dir, exist_ok=True)
    for ticker, points in history.items():
        ticker_path = os.path.join(history_dir, f"{ticker}.json")
        ticker_payload = {
            "generatedAt": now,
            "ticker": ticker,
            "history": points,
        }
        try:
            _atomic_write_json(ticker_path, ticker_payload)
            print(f"  â””â”€ {ticker_path} ({len(points)} ç­†)")
        except Exception as e:
            print(f"âš ï¸ å¯«å…¥ {ticker_path} å¤±æ•—ï¼š{e}")

    # 3. æ¸…é™¤å·²ç§»é™¤è‚¡ç¥¨çš„æ®˜ç•™ JSON
    try:
        existing_files = {f[:-5] for f in os.listdir(history_dir) if f.endswith('.json')}
        for orphan in existing_files - set(history.keys()):
            orphan_path = os.path.join(history_dir, f"{orphan}.json")
            os.remove(orphan_path)
            print(f"  ğŸ—‘ï¸  å·²åˆªé™¤æ®˜ç•™: {orphan_path}")
    except Exception as e:
        print(f"âš ï¸ æ¸…é™¤æ®˜ç•™æª”å¤±æ•—: {e}")

    return public_path
